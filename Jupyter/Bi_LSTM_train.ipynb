{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dongc\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import time\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "%run Bi_LSTM.py\n",
    "%run Word2Vec.py\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 여기부터 하면 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "from eunjeon import Mecab\n",
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mecab = Mecab()\n",
    "okt = Okt()\n",
    "W2V = Word2Vec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/자소서7.csv',index_col=0, engine='python', encoding='utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 섞기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index().drop(columns={'index'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = np.random.choice(df.index.values, len(df), replace=False)\n",
    "sampled_df = df.loc[rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = int(len(df) * 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category1</th>\n",
       "      <th>category2</th>\n",
       "      <th>jss</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category3</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>경영지원</th>\n",
       "      <td>1523</td>\n",
       "      <td>1523</td>\n",
       "      <td>1523</td>\n",
       "      <td>1523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>생산·물류</th>\n",
       "      <td>2475</td>\n",
       "      <td>2475</td>\n",
       "      <td>2475</td>\n",
       "      <td>2475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>서버·시스템</th>\n",
       "      <td>392</td>\n",
       "      <td>392</td>\n",
       "      <td>392</td>\n",
       "      <td>392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>영업·마케팅</th>\n",
       "      <td>3873</td>\n",
       "      <td>3873</td>\n",
       "      <td>3873</td>\n",
       "      <td>3873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>응용프로그래밍</th>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>인사</th>\n",
       "      <td>285</td>\n",
       "      <td>285</td>\n",
       "      <td>285</td>\n",
       "      <td>285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>재무·금융</th>\n",
       "      <td>1344</td>\n",
       "      <td>1344</td>\n",
       "      <td>1344</td>\n",
       "      <td>1344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           category1  category2   jss  label\n",
       "category3                                   \n",
       "경영지원            1523       1523  1523   1523\n",
       "생산·물류           2475       2475  2475   2475\n",
       "서버·시스템           392        392   392    392\n",
       "영업·마케팅          3873       3873  3873   3873\n",
       "응용프로그래밍          449        449   449    449\n",
       "인사               285        285   285    285\n",
       "재무·금융           1344       1344  1344   1344"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:dataset].groupby('category3').agg('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category1</th>\n",
       "      <th>category2</th>\n",
       "      <th>jss</th>\n",
       "      <th>label</th>\n",
       "      <th>category3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14044</th>\n",
       "      <td>응용프로그래밍</td>\n",
       "      <td>게임기획</td>\n",
       "      <td>[올리브영 내 마음속에 저장]\\n\\n타 H&amp;B스토어가 아닌 올리브영을 선택한 이유는...</td>\n",
       "      <td>6</td>\n",
       "      <td>응용프로그래밍</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7931</th>\n",
       "      <td>사무</td>\n",
       "      <td>판매·매장관리</td>\n",
       "      <td>[1년 후]\\nSPA 파트너로 입사 후, 처음 업무를 시작할 때 배우는 매장 청결관...</td>\n",
       "      <td>0</td>\n",
       "      <td>경영지원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3386</th>\n",
       "      <td>생산품질</td>\n",
       "      <td>안전·품질·검사·관리</td>\n",
       "      <td>[기본에 충실해야 한다]\\n\\n저는 동아리 및 봉사활동 활동을 할 때에 있어서 리더...</td>\n",
       "      <td>2</td>\n",
       "      <td>생산·물류</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12759</th>\n",
       "      <td>물류</td>\n",
       "      <td>구매관리</td>\n",
       "      <td>[아모레 퍼시픽의 실크로드를 위해]\\n입사 후 저는 제가 맡은 업무에서 인정받고, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>생산·물류</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11305</th>\n",
       "      <td>영업</td>\n",
       "      <td>영업관리</td>\n",
       "      <td>상대방에 대한 이해를 바탕으로 공감대를 잘 형성한다는 것이 제 장점입니다. 소대장 ...</td>\n",
       "      <td>3</td>\n",
       "      <td>영업·마케팅</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      category1    category2  \\\n",
       "14044   응용프로그래밍         게임기획   \n",
       "7931         사무      판매·매장관리   \n",
       "3386       생산품질  안전·품질·검사·관리   \n",
       "12759        물류         구매관리   \n",
       "11305        영업         영업관리   \n",
       "\n",
       "                                                     jss  label category3  \n",
       "14044  [올리브영 내 마음속에 저장]\\n\\n타 H&B스토어가 아닌 올리브영을 선택한 이유는...      6   응용프로그래밍  \n",
       "7931   [1년 후]\\nSPA 파트너로 입사 후, 처음 업무를 시작할 때 배우는 매장 청결관...      0      경영지원  \n",
       "3386   [기본에 충실해야 한다]\\n\\n저는 동아리 및 봉사활동 활동을 할 때에 있어서 리더...      2     생산·물류  \n",
       "12759  [아모레 퍼시픽의 실크로드를 위해]\\n입사 후 저는 제가 맡은 업무에서 인정받고, ...      2     생산·물류  \n",
       "11305  상대방에 대한 이해를 바탕으로 공감대를 잘 형성한다는 것이 제 장점입니다. 소대장 ...      3    영업·마케팅  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8fc2251cf1242928e05772b2a91cf37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=14773), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for txt in tqdm_notebook(df.jss):\n",
    "    data.append(okt.nouns(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 워드 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "tf.reset_default_graph()\n",
    "W2V = Word2Vec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = int(len(data)*0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 70% train, 30% test\n",
    "train_X = data[:dataset]\n",
    "train_Y = labels[:dataset]\n",
    "test_X = data[dataset:]\n",
    "test_Y = labels[dataset:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = len(df.category3.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_ = W2V.Convert2Vec(\"../data/word2vec_okt_nouns.model\",train_X)\n",
    "test_X_ = W2V.Convert2Vec(\"../data/word2vec_okt_nouns.model\",test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y_ = W2V.One_hot(train_Y)\n",
    "test_Y_ = W2V.One_hot(test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch_size = 32\n",
    "Total_size = len(train_X)\n",
    "Vector_size = 300 # 모델의 워드벡터 사이즈\n",
    "train_seq_length = [len(x) for x in train_X]\n",
    "test_seq_length = [len(x) for x in test_X]\n",
    "Maxseq_length = max(max(train_seq_length), max(test_seq_length))\n",
    "learning_rate = 0.001\n",
    "lstm_units = 128\n",
    "num_class = nb_classes\n",
    "training_epochs = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 그래프 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape = [None, Maxseq_length, Vector_size], name = 'X')\n",
    "Y = tf.placeholder(tf.float32, shape = [None, num_class], name = 'Y')\n",
    "seq_len = tf.placeholder(tf.int32, shape = [None])\n",
    "keep_prob = tf.placeholder(tf.float32, shape = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "BiLSTM = Bi_LSTM(lstm_units, num_class, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"loss\", reuse = tf.AUTO_REUSE):\n",
    "    logits = BiLSTM.logits(X, BiLSTM.W, BiLSTM.b, seq_len)\n",
    "    loss, optimizer = BiLSTM.model_build(logits, Y, learning_rate)\n",
    "prediction = tf.nn.softmax(logits)\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_batch = int(len(train_X) / Batch_size)\n",
    "test_batch = int(len(test_X) / Batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = \"./Bidirectional_LSTM_3/BiLSTM_model.ckpt\"\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "train_acc = []\n",
    "train_loss = []\n",
    "test_acc = []\n",
    "test_loss = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 세션 런"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session(config=config)\n",
    "init = tf.global_variables_initializer()\n",
    "start_time = time.time()\n",
    "sess.run(init)\n",
    "train_writer = tf.summary.FileWriter('./Bidirectional_LSTM_3', sess.graph)\n",
    "merged = BiLSTM.graph_build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da511c2276ec418685be54b45d6f2530",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=323), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 05 step : 0001 loss = 0.448818 accuracy= 0.906250\n",
      "epoch : 05 step : 0002 loss = 0.239373 accuracy= 0.968750\n",
      "epoch : 05 step : 0003 loss = 0.349640 accuracy= 0.937500\n",
      "epoch : 05 step : 0004 loss = 0.281838 accuracy= 0.968750\n",
      "epoch : 05 step : 0005 loss = 0.671867 accuracy= 0.781250\n",
      "epoch : 05 step : 0006 loss = 0.490136 accuracy= 0.875000\n",
      "epoch : 05 step : 0007 loss = 0.524950 accuracy= 0.875000\n",
      "epoch : 05 step : 0008 loss = 0.550493 accuracy= 0.843750\n",
      "epoch : 05 step : 0009 loss = 0.315222 accuracy= 0.937500\n",
      "epoch : 05 step : 0010 loss = 0.543034 accuracy= 0.843750\n",
      "epoch : 05 step : 0011 loss = 0.544982 accuracy= 0.781250\n",
      "epoch : 05 step : 0012 loss = 0.304158 accuracy= 0.906250\n",
      "epoch : 05 step : 0013 loss = 0.461321 accuracy= 0.781250\n",
      "epoch : 05 step : 0014 loss = 0.301683 accuracy= 0.937500\n",
      "epoch : 05 step : 0015 loss = 0.419736 accuracy= 0.875000\n",
      "epoch : 05 step : 0016 loss = 0.518554 accuracy= 0.875000\n",
      "epoch : 05 step : 0017 loss = 0.527335 accuracy= 0.906250\n",
      "epoch : 05 step : 0018 loss = 0.392715 accuracy= 0.906250\n",
      "epoch : 05 step : 0019 loss = 0.562683 accuracy= 0.781250\n",
      "epoch : 05 step : 0020 loss = 0.444954 accuracy= 0.875000\n",
      "epoch : 05 step : 0021 loss = 0.320130 accuracy= 0.937500\n",
      "epoch : 05 step : 0022 loss = 0.490701 accuracy= 0.812500\n",
      "epoch : 05 step : 0023 loss = 0.344082 accuracy= 0.937500\n",
      "epoch : 05 step : 0024 loss = 0.414607 accuracy= 0.781250\n",
      "epoch : 05 step : 0025 loss = 0.452738 accuracy= 0.906250\n",
      "epoch : 05 step : 0026 loss = 0.516428 accuracy= 0.843750\n",
      "epoch : 05 step : 0027 loss = 0.278681 accuracy= 0.937500\n",
      "epoch : 05 step : 0028 loss = 0.603982 accuracy= 0.812500\n",
      "epoch : 05 step : 0029 loss = 0.398547 accuracy= 0.875000\n",
      "epoch : 05 step : 0030 loss = 0.347802 accuracy= 0.906250\n",
      "epoch : 05 step : 0031 loss = 0.279663 accuracy= 0.937500\n",
      "epoch : 05 step : 0032 loss = 0.366277 accuracy= 0.875000\n",
      "epoch : 05 step : 0033 loss = 0.360886 accuracy= 0.875000\n",
      "epoch : 05 step : 0034 loss = 0.519526 accuracy= 0.843750\n",
      "epoch : 05 step : 0035 loss = 0.363245 accuracy= 0.875000\n",
      "epoch : 05 step : 0036 loss = 0.444989 accuracy= 0.843750\n",
      "epoch : 05 step : 0037 loss = 0.231024 accuracy= 0.968750\n",
      "epoch : 05 step : 0038 loss = 0.422005 accuracy= 0.906250\n",
      "epoch : 05 step : 0039 loss = 0.488823 accuracy= 0.843750\n",
      "epoch : 05 step : 0040 loss = 0.268061 accuracy= 0.968750\n",
      "epoch : 05 step : 0041 loss = 0.324323 accuracy= 0.906250\n",
      "epoch : 05 step : 0042 loss = 0.331724 accuracy= 0.906250\n",
      "epoch : 05 step : 0043 loss = 0.333454 accuracy= 0.937500\n",
      "epoch : 05 step : 0044 loss = 0.292818 accuracy= 0.906250\n",
      "epoch : 05 step : 0045 loss = 0.316976 accuracy= 0.906250\n",
      "epoch : 05 step : 0046 loss = 0.464644 accuracy= 0.875000\n",
      "epoch : 05 step : 0047 loss = 0.533688 accuracy= 0.843750\n",
      "epoch : 05 step : 0048 loss = 0.447218 accuracy= 0.937500\n",
      "epoch : 05 step : 0049 loss = 0.285440 accuracy= 0.968750\n",
      "epoch : 05 step : 0050 loss = 0.336926 accuracy= 0.906250\n",
      "epoch : 05 step : 0051 loss = 0.414522 accuracy= 0.906250\n",
      "epoch : 05 step : 0052 loss = 0.335192 accuracy= 0.937500\n",
      "epoch : 05 step : 0053 loss = 0.443327 accuracy= 0.875000\n",
      "epoch : 05 step : 0054 loss = 0.446110 accuracy= 0.875000\n",
      "epoch : 05 step : 0055 loss = 0.440516 accuracy= 0.906250\n",
      "epoch : 05 step : 0056 loss = 0.768926 accuracy= 0.781250\n",
      "epoch : 05 step : 0057 loss = 0.437102 accuracy= 0.875000\n",
      "epoch : 05 step : 0058 loss = 0.414572 accuracy= 0.875000\n",
      "epoch : 05 step : 0059 loss = 0.332276 accuracy= 0.968750\n",
      "epoch : 05 step : 0060 loss = 0.369951 accuracy= 0.968750\n",
      "epoch : 05 step : 0061 loss = 0.422692 accuracy= 0.875000\n",
      "epoch : 05 step : 0062 loss = 0.490496 accuracy= 0.906250\n",
      "epoch : 05 step : 0063 loss = 0.299715 accuracy= 0.875000\n",
      "epoch : 05 step : 0064 loss = 0.388250 accuracy= 0.906250\n",
      "epoch : 05 step : 0065 loss = 0.415712 accuracy= 0.968750\n",
      "epoch : 05 step : 0066 loss = 0.230189 accuracy= 0.968750\n",
      "epoch : 05 step : 0067 loss = 0.375420 accuracy= 0.906250\n",
      "epoch : 05 step : 0068 loss = 0.387676 accuracy= 0.937500\n",
      "epoch : 05 step : 0069 loss = 0.362335 accuracy= 0.843750\n",
      "epoch : 05 step : 0070 loss = 0.382056 accuracy= 0.875000\n",
      "epoch : 05 step : 0071 loss = 0.260918 accuracy= 0.937500\n",
      "epoch : 05 step : 0072 loss = 0.353107 accuracy= 0.875000\n",
      "epoch : 05 step : 0073 loss = 0.491900 accuracy= 0.875000\n",
      "epoch : 05 step : 0074 loss = 0.313710 accuracy= 0.906250\n",
      "epoch : 05 step : 0075 loss = 0.478168 accuracy= 0.812500\n",
      "epoch : 05 step : 0076 loss = 0.318419 accuracy= 0.937500\n",
      "epoch : 05 step : 0077 loss = 0.725558 accuracy= 0.875000\n",
      "epoch : 05 step : 0078 loss = 0.295993 accuracy= 0.906250\n",
      "epoch : 05 step : 0079 loss = 0.490435 accuracy= 0.906250\n",
      "epoch : 05 step : 0080 loss = 0.258962 accuracy= 0.968750\n",
      "epoch : 05 step : 0081 loss = 0.540631 accuracy= 0.843750\n",
      "epoch : 05 step : 0082 loss = 0.461069 accuracy= 0.875000\n",
      "epoch : 05 step : 0083 loss = 0.355400 accuracy= 0.875000\n",
      "epoch : 05 step : 0084 loss = 0.467474 accuracy= 0.906250\n",
      "epoch : 05 step : 0085 loss = 0.492775 accuracy= 0.781250\n",
      "epoch : 05 step : 0086 loss = 0.533766 accuracy= 0.843750\n",
      "epoch : 05 step : 0087 loss = 0.318746 accuracy= 0.968750\n",
      "epoch : 05 step : 0088 loss = 0.330568 accuracy= 0.875000\n",
      "epoch : 05 step : 0089 loss = 0.491085 accuracy= 0.875000\n",
      "epoch : 05 step : 0090 loss = 0.541433 accuracy= 0.781250\n",
      "epoch : 05 step : 0091 loss = 0.361970 accuracy= 0.875000\n",
      "epoch : 05 step : 0092 loss = 0.675188 accuracy= 0.781250\n",
      "epoch : 05 step : 0093 loss = 0.430137 accuracy= 0.906250\n",
      "epoch : 05 step : 0094 loss = 0.563812 accuracy= 0.843750\n",
      "epoch : 05 step : 0095 loss = 0.398363 accuracy= 0.843750\n",
      "epoch : 05 step : 0096 loss = 0.403134 accuracy= 0.875000\n",
      "epoch : 05 step : 0097 loss = 0.356345 accuracy= 0.906250\n",
      "epoch : 05 step : 0098 loss = 0.347298 accuracy= 0.968750\n",
      "epoch : 05 step : 0099 loss = 0.671371 accuracy= 0.843750\n",
      "epoch : 05 step : 0100 loss = 0.343705 accuracy= 0.937500\n",
      "epoch : 05 step : 0101 loss = 0.479580 accuracy= 0.906250\n",
      "epoch : 05 step : 0102 loss = 0.392302 accuracy= 0.875000\n",
      "epoch : 05 step : 0103 loss = 0.440952 accuracy= 0.937500\n",
      "epoch : 05 step : 0104 loss = 0.568140 accuracy= 0.843750\n",
      "epoch : 05 step : 0105 loss = 0.245492 accuracy= 0.968750\n",
      "epoch : 05 step : 0106 loss = 0.354699 accuracy= 0.875000\n",
      "epoch : 05 step : 0107 loss = 0.483798 accuracy= 0.812500\n",
      "epoch : 05 step : 0108 loss = 0.647050 accuracy= 0.812500\n",
      "epoch : 05 step : 0109 loss = 0.364343 accuracy= 0.906250\n",
      "epoch : 05 step : 0110 loss = 0.320590 accuracy= 0.875000\n",
      "epoch : 05 step : 0111 loss = 0.411058 accuracy= 0.906250\n",
      "epoch : 05 step : 0112 loss = 0.402316 accuracy= 0.875000\n",
      "epoch : 05 step : 0113 loss = 0.519125 accuracy= 0.843750\n",
      "epoch : 05 step : 0114 loss = 0.279177 accuracy= 0.937500\n",
      "epoch : 05 step : 0115 loss = 0.590654 accuracy= 0.781250\n",
      "epoch : 05 step : 0116 loss = 0.542022 accuracy= 0.875000\n",
      "epoch : 05 step : 0117 loss = 0.337612 accuracy= 0.875000\n",
      "epoch : 05 step : 0118 loss = 0.402510 accuracy= 0.843750\n",
      "epoch : 05 step : 0119 loss = 0.437219 accuracy= 0.875000\n",
      "epoch : 05 step : 0120 loss = 0.366920 accuracy= 0.906250\n",
      "epoch : 05 step : 0121 loss = 0.484803 accuracy= 0.906250\n",
      "epoch : 05 step : 0122 loss = 0.535020 accuracy= 0.812500\n",
      "epoch : 05 step : 0123 loss = 0.656571 accuracy= 0.781250\n",
      "epoch : 05 step : 0124 loss = 0.479177 accuracy= 0.875000\n",
      "epoch : 05 step : 0125 loss = 0.370138 accuracy= 0.875000\n",
      "epoch : 05 step : 0126 loss = 0.434601 accuracy= 0.875000\n",
      "epoch : 05 step : 0127 loss = 0.262206 accuracy= 0.906250\n",
      "epoch : 05 step : 0128 loss = 0.541456 accuracy= 0.812500\n",
      "epoch : 05 step : 0129 loss = 0.464804 accuracy= 0.843750\n",
      "epoch : 05 step : 0130 loss = 0.557909 accuracy= 0.906250\n",
      "epoch : 05 step : 0131 loss = 0.353424 accuracy= 0.937500\n",
      "epoch : 05 step : 0132 loss = 0.528078 accuracy= 0.843750\n",
      "epoch : 05 step : 0133 loss = 0.343971 accuracy= 0.937500\n",
      "epoch : 05 step : 0134 loss = 0.663676 accuracy= 0.812500\n",
      "epoch : 05 step : 0135 loss = 0.419385 accuracy= 0.906250\n",
      "epoch : 05 step : 0136 loss = 0.384941 accuracy= 0.843750\n",
      "epoch : 05 step : 0137 loss = 0.407387 accuracy= 0.875000\n",
      "epoch : 05 step : 0138 loss = 0.452689 accuracy= 0.875000\n",
      "epoch : 05 step : 0139 loss = 0.503532 accuracy= 0.875000\n",
      "epoch : 05 step : 0140 loss = 0.288029 accuracy= 0.937500\n",
      "epoch : 05 step : 0141 loss = 0.579053 accuracy= 0.781250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 05 step : 0142 loss = 0.413894 accuracy= 0.906250\n",
      "epoch : 05 step : 0143 loss = 0.481418 accuracy= 0.875000\n",
      "epoch : 05 step : 0144 loss = 0.522869 accuracy= 0.875000\n",
      "epoch : 05 step : 0145 loss = 0.385237 accuracy= 0.843750\n",
      "epoch : 05 step : 0146 loss = 0.422976 accuracy= 0.906250\n",
      "epoch : 05 step : 0147 loss = 0.403772 accuracy= 0.937500\n",
      "epoch : 05 step : 0148 loss = 0.718124 accuracy= 0.750000\n",
      "epoch : 05 step : 0149 loss = 0.357649 accuracy= 0.968750\n",
      "epoch : 05 step : 0150 loss = 0.489764 accuracy= 0.812500\n",
      "epoch : 05 step : 0151 loss = 0.493045 accuracy= 0.843750\n",
      "epoch : 05 step : 0152 loss = 0.464060 accuracy= 0.875000\n",
      "epoch : 05 step : 0153 loss = 0.552883 accuracy= 0.875000\n",
      "epoch : 05 step : 0154 loss = 0.343497 accuracy= 0.937500\n",
      "epoch : 05 step : 0155 loss = 0.538230 accuracy= 0.812500\n",
      "epoch : 05 step : 0156 loss = 0.266071 accuracy= 0.968750\n",
      "epoch : 05 step : 0157 loss = 0.308671 accuracy= 0.968750\n",
      "epoch : 05 step : 0158 loss = 0.662360 accuracy= 0.781250\n",
      "epoch : 05 step : 0159 loss = 0.349950 accuracy= 0.937500\n",
      "epoch : 05 step : 0160 loss = 0.432161 accuracy= 0.875000\n",
      "epoch : 05 step : 0161 loss = 0.521809 accuracy= 0.781250\n",
      "epoch : 05 step : 0162 loss = 0.347902 accuracy= 0.875000\n",
      "epoch : 05 step : 0163 loss = 0.331602 accuracy= 0.937500\n",
      "epoch : 05 step : 0164 loss = 0.213873 accuracy= 1.000000\n",
      "epoch : 05 step : 0165 loss = 0.393089 accuracy= 0.906250\n",
      "epoch : 05 step : 0166 loss = 0.436058 accuracy= 0.812500\n",
      "epoch : 05 step : 0167 loss = 0.426425 accuracy= 0.906250\n",
      "epoch : 05 step : 0168 loss = 0.488954 accuracy= 0.875000\n",
      "epoch : 05 step : 0169 loss = 0.352055 accuracy= 0.875000\n",
      "epoch : 05 step : 0170 loss = 0.495737 accuracy= 0.843750\n",
      "epoch : 05 step : 0171 loss = 0.347745 accuracy= 0.906250\n",
      "epoch : 05 step : 0172 loss = 0.398462 accuracy= 0.937500\n",
      "epoch : 05 step : 0173 loss = 0.335772 accuracy= 0.937500\n",
      "epoch : 05 step : 0174 loss = 0.345043 accuracy= 0.937500\n",
      "epoch : 05 step : 0175 loss = 0.427052 accuracy= 0.812500\n",
      "epoch : 05 step : 0176 loss = 0.370201 accuracy= 0.875000\n",
      "epoch : 05 step : 0177 loss = 0.335006 accuracy= 0.875000\n",
      "epoch : 05 step : 0178 loss = 0.418850 accuracy= 0.812500\n",
      "epoch : 05 step : 0179 loss = 0.465107 accuracy= 0.906250\n",
      "epoch : 05 step : 0180 loss = 0.516232 accuracy= 0.875000\n",
      "epoch : 05 step : 0181 loss = 0.439431 accuracy= 0.875000\n",
      "epoch : 05 step : 0182 loss = 0.668320 accuracy= 0.750000\n",
      "epoch : 05 step : 0183 loss = 0.264628 accuracy= 0.968750\n",
      "epoch : 05 step : 0184 loss = 0.516501 accuracy= 0.875000\n",
      "epoch : 05 step : 0185 loss = 0.325760 accuracy= 0.968750\n",
      "epoch : 05 step : 0186 loss = 0.591280 accuracy= 0.843750\n",
      "epoch : 05 step : 0187 loss = 0.478906 accuracy= 0.843750\n",
      "epoch : 05 step : 0188 loss = 0.261085 accuracy= 0.937500\n",
      "epoch : 05 step : 0189 loss = 0.667967 accuracy= 0.718750\n",
      "epoch : 05 step : 0190 loss = 0.525566 accuracy= 0.812500\n",
      "epoch : 05 step : 0191 loss = 0.524999 accuracy= 0.843750\n",
      "epoch : 05 step : 0192 loss = 0.561095 accuracy= 0.718750\n",
      "epoch : 05 step : 0193 loss = 0.494393 accuracy= 0.875000\n",
      "epoch : 05 step : 0194 loss = 0.376277 accuracy= 0.843750\n",
      "epoch : 05 step : 0195 loss = 0.325570 accuracy= 0.906250\n",
      "epoch : 05 step : 0196 loss = 0.505384 accuracy= 0.906250\n",
      "epoch : 05 step : 0197 loss = 0.481263 accuracy= 0.843750\n",
      "epoch : 05 step : 0198 loss = 0.259122 accuracy= 0.906250\n",
      "epoch : 05 step : 0199 loss = 0.465704 accuracy= 0.843750\n",
      "epoch : 05 step : 0200 loss = 0.426568 accuracy= 0.937500\n",
      "epoch : 05 step : 0201 loss = 0.391921 accuracy= 0.906250\n",
      "epoch : 05 step : 0202 loss = 0.480186 accuracy= 0.843750\n",
      "epoch : 05 step : 0203 loss = 0.385632 accuracy= 0.937500\n",
      "epoch : 05 step : 0204 loss = 0.423870 accuracy= 0.875000\n",
      "epoch : 05 step : 0205 loss = 0.325921 accuracy= 0.875000\n",
      "epoch : 05 step : 0206 loss = 0.481721 accuracy= 0.781250\n",
      "epoch : 05 step : 0207 loss = 0.338420 accuracy= 0.875000\n",
      "epoch : 05 step : 0208 loss = 0.475735 accuracy= 0.812500\n",
      "epoch : 05 step : 0209 loss = 0.400160 accuracy= 0.875000\n",
      "epoch : 05 step : 0210 loss = 0.508097 accuracy= 0.875000\n",
      "epoch : 05 step : 0211 loss = 0.525291 accuracy= 0.781250\n",
      "epoch : 05 step : 0212 loss = 0.553187 accuracy= 0.843750\n",
      "epoch : 05 step : 0213 loss = 0.428330 accuracy= 0.875000\n",
      "epoch : 05 step : 0214 loss = 0.564666 accuracy= 0.812500\n",
      "epoch : 05 step : 0215 loss = 0.756881 accuracy= 0.750000\n",
      "epoch : 05 step : 0216 loss = 0.517833 accuracy= 0.812500\n",
      "epoch : 05 step : 0217 loss = 0.427070 accuracy= 0.875000\n",
      "epoch : 05 step : 0218 loss = 0.368223 accuracy= 0.906250\n",
      "epoch : 05 step : 0219 loss = 0.572835 accuracy= 0.750000\n",
      "epoch : 05 step : 0220 loss = 0.469712 accuracy= 0.875000\n",
      "epoch : 05 step : 0221 loss = 0.411387 accuracy= 0.843750\n",
      "epoch : 05 step : 0222 loss = 0.742681 accuracy= 0.656250\n",
      "epoch : 05 step : 0223 loss = 0.287503 accuracy= 0.968750\n",
      "epoch : 05 step : 0224 loss = 0.481765 accuracy= 0.812500\n",
      "epoch : 05 step : 0225 loss = 0.595303 accuracy= 0.781250\n",
      "epoch : 05 step : 0226 loss = 0.525436 accuracy= 0.843750\n",
      "epoch : 05 step : 0227 loss = 0.452446 accuracy= 0.937500\n",
      "epoch : 05 step : 0228 loss = 0.436192 accuracy= 0.812500\n",
      "epoch : 05 step : 0229 loss = 0.592324 accuracy= 0.750000\n",
      "epoch : 05 step : 0230 loss = 0.384002 accuracy= 0.812500\n",
      "epoch : 05 step : 0231 loss = 0.554603 accuracy= 0.843750\n",
      "epoch : 05 step : 0232 loss = 0.466602 accuracy= 0.812500\n",
      "epoch : 05 step : 0233 loss = 0.444963 accuracy= 0.937500\n",
      "epoch : 05 step : 0234 loss = 0.467638 accuracy= 0.843750\n",
      "epoch : 05 step : 0235 loss = 0.320357 accuracy= 0.843750\n",
      "epoch : 05 step : 0236 loss = 0.389525 accuracy= 0.906250\n",
      "epoch : 05 step : 0237 loss = 0.506563 accuracy= 0.875000\n",
      "epoch : 05 step : 0238 loss = 0.486200 accuracy= 0.843750\n",
      "epoch : 05 step : 0239 loss = 0.679989 accuracy= 0.750000\n",
      "epoch : 05 step : 0240 loss = 0.406873 accuracy= 0.875000\n",
      "epoch : 05 step : 0241 loss = 0.361323 accuracy= 0.906250\n",
      "epoch : 05 step : 0242 loss = 0.286451 accuracy= 0.875000\n",
      "epoch : 05 step : 0243 loss = 0.350761 accuracy= 0.906250\n",
      "epoch : 05 step : 0244 loss = 0.466411 accuracy= 0.906250\n",
      "epoch : 05 step : 0245 loss = 0.268873 accuracy= 0.968750\n",
      "epoch : 05 step : 0246 loss = 0.483010 accuracy= 0.843750\n",
      "epoch : 05 step : 0247 loss = 0.258689 accuracy= 0.968750\n",
      "epoch : 05 step : 0248 loss = 0.570116 accuracy= 0.812500\n",
      "epoch : 05 step : 0249 loss = 0.321958 accuracy= 0.937500\n",
      "epoch : 05 step : 0250 loss = 0.377238 accuracy= 0.906250\n",
      "epoch : 05 step : 0251 loss = 0.555055 accuracy= 0.875000\n",
      "epoch : 05 step : 0252 loss = 0.548052 accuracy= 0.843750\n",
      "epoch : 05 step : 0253 loss = 0.386310 accuracy= 0.812500\n",
      "epoch : 05 step : 0254 loss = 0.316879 accuracy= 0.937500\n",
      "epoch : 05 step : 0255 loss = 0.363428 accuracy= 0.875000\n",
      "epoch : 05 step : 0256 loss = 0.512365 accuracy= 0.843750\n",
      "epoch : 05 step : 0257 loss = 0.227069 accuracy= 0.968750\n",
      "epoch : 05 step : 0258 loss = 0.484579 accuracy= 0.906250\n",
      "epoch : 05 step : 0259 loss = 0.747928 accuracy= 0.750000\n",
      "epoch : 05 step : 0260 loss = 0.591135 accuracy= 0.812500\n",
      "epoch : 05 step : 0261 loss = 0.596782 accuracy= 0.812500\n",
      "epoch : 05 step : 0262 loss = 0.583534 accuracy= 0.750000\n",
      "epoch : 05 step : 0263 loss = 0.376838 accuracy= 0.843750\n",
      "epoch : 05 step : 0264 loss = 0.515042 accuracy= 0.843750\n",
      "epoch : 05 step : 0265 loss = 0.395977 accuracy= 0.875000\n",
      "epoch : 05 step : 0266 loss = 0.592015 accuracy= 0.781250\n",
      "epoch : 05 step : 0267 loss = 0.446338 accuracy= 0.843750\n",
      "epoch : 05 step : 0268 loss = 0.348456 accuracy= 0.906250\n",
      "epoch : 05 step : 0269 loss = 0.544743 accuracy= 0.718750\n",
      "epoch : 05 step : 0270 loss = 0.484306 accuracy= 0.875000\n",
      "epoch : 05 step : 0271 loss = 0.517848 accuracy= 0.812500\n",
      "epoch : 05 step : 0272 loss = 0.508731 accuracy= 0.875000\n",
      "epoch : 05 step : 0273 loss = 0.345692 accuracy= 0.875000\n",
      "epoch : 05 step : 0274 loss = 0.354331 accuracy= 0.937500\n",
      "epoch : 05 step : 0275 loss = 0.302787 accuracy= 0.906250\n",
      "epoch : 05 step : 0276 loss = 0.446587 accuracy= 0.875000\n",
      "epoch : 05 step : 0277 loss = 0.544177 accuracy= 0.843750\n",
      "epoch : 05 step : 0278 loss = 0.529394 accuracy= 0.781250\n",
      "epoch : 05 step : 0279 loss = 0.437507 accuracy= 0.937500\n",
      "epoch : 05 step : 0280 loss = 0.502501 accuracy= 0.843750\n",
      "epoch : 05 step : 0281 loss = 0.647992 accuracy= 0.718750\n",
      "epoch : 05 step : 0282 loss = 0.507410 accuracy= 0.906250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 05 step : 0283 loss = 0.607685 accuracy= 0.812500\n",
      "epoch : 05 step : 0284 loss = 0.291334 accuracy= 0.968750\n",
      "epoch : 05 step : 0285 loss = 0.746136 accuracy= 0.781250\n",
      "epoch : 05 step : 0286 loss = 0.388807 accuracy= 0.906250\n",
      "epoch : 05 step : 0287 loss = 0.359632 accuracy= 0.906250\n",
      "epoch : 05 step : 0288 loss = 0.444398 accuracy= 0.875000\n",
      "epoch : 05 step : 0289 loss = 0.751837 accuracy= 0.750000\n",
      "epoch : 05 step : 0290 loss = 0.212810 accuracy= 0.968750\n",
      "epoch : 05 step : 0291 loss = 0.547731 accuracy= 0.750000\n",
      "epoch : 05 step : 0292 loss = 0.431992 accuracy= 0.843750\n",
      "epoch : 05 step : 0293 loss = 0.289422 accuracy= 0.906250\n",
      "epoch : 05 step : 0294 loss = 0.634811 accuracy= 0.781250\n",
      "epoch : 05 step : 0295 loss = 0.495063 accuracy= 0.875000\n",
      "epoch : 05 step : 0296 loss = 0.438111 accuracy= 0.875000\n",
      "epoch : 05 step : 0297 loss = 0.412545 accuracy= 0.875000\n",
      "epoch : 05 step : 0298 loss = 0.488302 accuracy= 0.875000\n",
      "epoch : 05 step : 0299 loss = 0.335395 accuracy= 0.968750\n",
      "epoch : 05 step : 0300 loss = 0.527401 accuracy= 0.812500\n",
      "epoch : 05 step : 0301 loss = 0.332640 accuracy= 0.875000\n",
      "epoch : 05 step : 0302 loss = 0.557056 accuracy= 0.843750\n",
      "epoch : 05 step : 0303 loss = 0.342838 accuracy= 0.937500\n",
      "epoch : 05 step : 0304 loss = 0.385026 accuracy= 0.875000\n",
      "epoch : 05 step : 0305 loss = 0.376718 accuracy= 0.781250\n",
      "epoch : 05 step : 0306 loss = 0.556265 accuracy= 0.843750\n",
      "epoch : 05 step : 0307 loss = 0.569165 accuracy= 0.843750\n",
      "epoch : 05 step : 0308 loss = 0.417536 accuracy= 0.812500\n",
      "epoch : 05 step : 0309 loss = 0.570303 accuracy= 0.812500\n",
      "epoch : 05 step : 0310 loss = 0.527577 accuracy= 0.812500\n",
      "epoch : 05 step : 0311 loss = 0.399257 accuracy= 0.937500\n",
      "epoch : 05 step : 0312 loss = 0.459627 accuracy= 0.875000\n",
      "epoch : 05 step : 0313 loss = 0.437452 accuracy= 0.875000\n",
      "epoch : 05 step : 0314 loss = 0.306451 accuracy= 0.906250\n",
      "epoch : 05 step : 0315 loss = 0.467397 accuracy= 0.875000\n",
      "epoch : 05 step : 0316 loss = 0.516670 accuracy= 0.875000\n",
      "epoch : 05 step : 0317 loss = 0.574987 accuracy= 0.875000\n",
      "epoch : 05 step : 0318 loss = 0.487581 accuracy= 0.906250\n",
      "epoch : 05 step : 0319 loss = 0.610209 accuracy= 0.781250\n",
      "epoch : 05 step : 0320 loss = 0.388612 accuracy= 0.875000\n",
      "epoch : 05 step : 0321 loss = 0.546965 accuracy= 0.781250\n",
      "epoch : 05 step : 0322 loss = 0.419695 accuracy= 0.875000\n",
      "epoch : 05 step : 0323 loss = 0.316455 accuracy= 0.937500\n",
      "\n",
      "0.44190635386819804 0.8713235294117637\n",
      "Test cases, could take few minutes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f06ce6d967243a0ba5a44dc5d69f50d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=138), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<Train> Loss = 0.441906 Accuracy = 0.871324\n",
      "<Test> Loss = 1.387857 Accuracy = 0.552989\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate object of type \"<class 'numpy.float64'>\"; only pd.Series, pd.DataFrame, and pd.Panel (deprecated) objs are valid",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-1da25fdf1eb6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"<Train> Loss = {:.6f} Accuracy = {:.6f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mavg_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mavg_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"<Test> Loss = {:.6f} Accuracy = {:.6f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_avg_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_avg_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     \u001b[0mtrain_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mavg_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m     \u001b[0mtrain_acc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mavg_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[0mtest_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_avg_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mappend\u001b[1;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[0;32m   6199\u001b[0m         return concat(to_concat, ignore_index=ignore_index,\n\u001b[0;32m   6200\u001b[0m                       \u001b[0mverify_integrity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6201\u001b[1;33m                       sort=sort)\n\u001b[0m\u001b[0;32m   6202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6203\u001b[0m     def join(self, other, on=None, how='left', lsuffix='', rsuffix='',\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    223\u001b[0m                        \u001b[0mkeys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m                        \u001b[0mverify_integrity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 225\u001b[1;33m                        copy=copy, sort=sort)\n\u001b[0m\u001b[0;32m    226\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, objs, axis, join, join_axes, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    284\u001b[0m                        \u001b[1;34m' only pd.Series, pd.DataFrame, and pd.Panel'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m                        ' (deprecated) objs are valid'.format(type(obj)))\n\u001b[1;32m--> 286\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m             \u001b[1;31m# consolidate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot concatenate object of type \"<class 'numpy.float64'>\"; only pd.Series, pd.DataFrame, and pd.Panel (deprecated) objs are valid"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):  \n",
    "\n",
    "    avg_acc, avg_loss = 0. , 0.\n",
    "    mask = np.random.permutation(len(train_X_))\n",
    "    train_X_ = train_X_[mask]\n",
    "    train_Y_ = train_Y_[mask]\n",
    "\n",
    "    for step in tqdm_notebook(range(total_batch)):\n",
    "\n",
    "        train_batch_X = train_X_[step*Batch_size : step*Batch_size+Batch_size]\n",
    "        train_batch_Y = train_Y_[step*Batch_size : step*Batch_size+Batch_size]\n",
    "        batch_seq_length = train_seq_length[step*Batch_size : step*Batch_size+Batch_size]\n",
    "\n",
    "        train_batch_X = W2V.Zero_padding(train_batch_X, Batch_size, Maxseq_length, Vector_size)\n",
    "\n",
    "        sess.run(optimizer, feed_dict={X: train_batch_X, Y: train_batch_Y, seq_len: batch_seq_length})\n",
    "        # Compute average loss\n",
    "        loss_ = sess.run(loss, feed_dict={X: train_batch_X, Y: train_batch_Y, seq_len: batch_seq_length,\n",
    "                                          keep_prob : 0.75})\n",
    "        avg_loss += loss_ / total_batch\n",
    "\n",
    "        acc = sess.run(accuracy , feed_dict={X: train_batch_X, Y: train_batch_Y, seq_len: batch_seq_length,\n",
    "                                             keep_prob : 0.75})\n",
    "        avg_acc += acc / total_batch\n",
    "        print(\"epoch : {:02d} step : {:04d} loss = {:.6f} accuracy= {:.6f}\".format(epoch+1, step+1, loss_, acc))\n",
    "\n",
    "    summary = sess.run(merged, feed_dict = {BiLSTM.loss : avg_loss, BiLSTM.acc : avg_acc})       \n",
    "    train_writer.add_summary(summary, epoch)\n",
    "\n",
    "    t_avg_acc, t_avg_loss = 0. , 0.\n",
    "    print(avg_loss, avg_acc)\n",
    "    print(\"Test cases, could take few minutes\")\n",
    "    \n",
    "    for step in tqdm_notebook(range(test_batch)):\n",
    "\n",
    "        test_batch_X = test_X_[step*Batch_size : step*Batch_size+Batch_size]\n",
    "        test_batch_Y = test_Y_[step*Batch_size : step*Batch_size+Batch_size]\n",
    "        batch_seq_length = test_seq_length[step*Batch_size : step*Batch_size+Batch_size]\n",
    "\n",
    "        test_batch_X = W2V.Zero_padding(test_batch_X, Batch_size, Maxseq_length, Vector_size)\n",
    "\n",
    "        # Compute average loss\n",
    "        loss2 = sess.run(loss, feed_dict={X: test_batch_X, Y: test_batch_Y, seq_len: batch_seq_length,\n",
    "                                          keep_prob : 1.0})\n",
    "        t_avg_loss += loss2 / test_batch\n",
    "\n",
    "        t_acc = sess.run(accuracy , feed_dict={X: test_batch_X, Y: test_batch_Y, seq_len: batch_seq_length,\n",
    "                                               keep_prob : 1.0})\n",
    "        t_avg_acc += t_acc / test_batch\n",
    "\n",
    "    print(\"<Train> Loss = {:.6f} Accuracy = {:.6f}\".format(avg_loss, avg_acc))\n",
    "    print(\"<Test> Loss = {:.6f} Accuracy = {:.6f}\".format(t_avg_loss, t_avg_acc))\n",
    "    train_loss.append(avg_loss)\n",
    "    train_acc.append(avg_acc)\n",
    "    test_loss.append(t_avg_loss)\n",
    "    test_acc.append(t_avg_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = pd.DataFrame({\"train_loss\":train_loss})\n",
    "train_acc = pd.DataFrame({\"train_acc\":train_acc})\n",
    "test_loss = pd.DataFrame({\"test_loss\":test_loss})\n",
    "test_acc = pd.DataFrame({\"test_acc\":test_acc})\n",
    "df = pd.concat([train_loss,train_acc,test_loss,test_acc], axis = 1)\n",
    "df.to_csv(\"./Bidirectional_LSTM_3/loss_accuracy.csv\", sep =\",\", index=False)\n",
    "\n",
    "train_writer.close()\n",
    "duration = time.time() - start_time\n",
    "minute = int(duration / 60)\n",
    "second = int(duration) % 60\n",
    "print(\"%dminutes %dseconds\" % (minute,second))\n",
    "save_path = saver.save(sess, modelName)\n",
    "\n",
    "print ('save_path',save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
